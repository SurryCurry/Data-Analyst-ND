{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Data Wrangling Project\n",
    "###### Suraag Gupta\n",
    "\n",
    "#### Map Area: Columbus, OH USA\n",
    "The OSM dataset I chose was for Columbus, OH simply because it is where I live.\n",
    "## Processing the Dataset\n",
    "I started off with importing the libraries I knew I would be needing and the OSM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from pymongo import MongoClient\n",
    "import pprint, re, json, codecs\n",
    "from OSMAudit import *\n",
    "from OSMProcess import *\n",
    "from OSMShape import *\n",
    "\n",
    "OSM_FILE=\"ColumbusOH.osm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Preliminary Information\n",
    "Then I began running all the functions that I had worked on in the CaseStudy lessons.\n",
    "I used the count_tags, key_type, process_users, & get_address_types functions to get a sense of the data I was looking at and what I would need to do moving forward.\n",
    "\n",
    "Thankfully, there were no problems in running this information, so I managed to move on fairly quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Auditing\n",
    "Looking at the different addr types from the output of the previous function, I decided that I should go through the city, country, county, postcode, & state keys alongside the street to ensure that all the values were uniform and as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'101': set(['E Dublin Granville Rd #101']),\n",
      " '105': set(['Mill St Suite 105']),\n",
      " '250': set(['Chambers Rd #250']),\n",
      " '2D': set(['Copeland Mill Rd #2D']),\n",
      " '320': set(['W Old Wilson Bridge Rd #320']),\n",
      " '762': set(['State Route 762']),\n",
      " '8877': set(['8877']),\n",
      " '8897': set(['8897']),\n",
      " '8906': set(['8906']),\n",
      " 'Ave': set(['N Cassady Ave']),\n",
      " 'Blvd': set(['Channingway Blvd']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'Center': set(['Easton Town Center', 'Mc Naughten Center', 'Tremont Center']),\n",
      " 'Circle': set(['Ellington Circle', 'Gateway Circle', 'Parkcenter Circle']),\n",
      " 'Crossing': set(['Morse Crossing']),\n",
      " 'Dr': set(['Auto Mall Dr',\n",
      "            'Green Meadows Dr',\n",
      "            'Humphries Dr',\n",
      "            'Rentra Dr',\n",
      "            'Wake Dr',\n",
      "            'Westpoint Plaza Dr',\n",
      "            'Westpointe Plaza Dr']),\n",
      " 'Dr.': set(['Centerpoint Dr.', 'Christopher John Dr.', 'Mark Andrew Dr.']),\n",
      " 'East': set(['Byers Circle East',\n",
      "              'Easton Loop East',\n",
      "              'New Albany Road East',\n",
      "              'The Strand East']),\n",
      " 'Gateway': set(['International Gateway']),\n",
      " 'Loop': set(['Nemain Loop']),\n",
      " 'Main': set(['College and Main']),\n",
      " 'Mall': set(['Kenny Centre Mall', 'Worthington Mall']),\n",
      " 'N': set(['Coventry Woods Drive N']),\n",
      " 'North': set(['College Road North',\n",
      "               'Freeway Drive North',\n",
      "               'Hill Road North',\n",
      "               'Liberty Road North',\n",
      "               'Metro Place North']),\n",
      " 'Northwest': set(['Beech Road Northwest',\n",
      "                   'Blacklick-Eastern Road Northwest']),\n",
      " 'Oval': set(['Easton Oval', \"Murphy's Oval\"]),\n",
      " 'Park': set(['Taylor Park']),\n",
      " 'Pike': set(['Columbus Pike', 'Jackson Pike', 'Winchester Pike']),\n",
      " 'Pkwy': set(['Blazer Pkwy']),\n",
      " 'Plaza': set(['Nationwide Plaza', 'Riverside Plaza']),\n",
      " 'RD': set(['POWELL RD']),\n",
      " 'Rd': set(['Alkire Rd',\n",
      "            'Caine Rd',\n",
      "            'Courtright Rd',\n",
      "            'Edington Rd',\n",
      "            'Fodor Rd',\n",
      "            'Hilliard-Rome Rd',\n",
      "            'Liberty Commons Rd',\n",
      "            'Norton Rd',\n",
      "            'Ridgeview Rd',\n",
      "            'Roberts Rd',\n",
      "            'S Hamilton Rd',\n",
      "            'Stringtown Rd']),\n",
      " 'Rd.': set(['E. Dublin Granville Rd.']),\n",
      " 'S': set(['Weaver Court S']),\n",
      " 'S.': set(['Heritage Club Drive S.']),\n",
      " 'SW': set(['National Rd SW']),\n",
      " 'South': set(['Green Pointe Drive South',\n",
      "               'Hill Road South',\n",
      "               'Metro Place South']),\n",
      " 'Southwest': set(['Broad Street Southwest', 'National Road Southwest']),\n",
      " 'St': set(['E Broad St',\n",
      "            'Hazelton St',\n",
      "            'Market St',\n",
      "            'N High St',\n",
      "            'S High St']),\n",
      " 'St.': set(['N. High St.']),\n",
      " 'Station': set(['Easton Station']),\n",
      " 'Strand': set(['The Strand']),\n",
      " 'Way': set(['Battle Creek Way',\n",
      "             'Bobcat Way',\n",
      "             'Gadston Way',\n",
      "             'Ikea Way',\n",
      "             'Liberation Way',\n",
      "             'Liberty Way',\n",
      "             'Little Turtle Way',\n",
      "             'Stockton Trail Way',\n",
      "             'Townsfair Way']),\n",
      " 'West': set(['County Line Road West',\n",
      "              'Easton Loop West',\n",
      "              'New Albany Road West',\n",
      "              'The Strand West'])}\n"
     ]
    }
   ],
   "source": [
    "with open(OSM_FILE, 'r') as columbus:\n",
    "    audit_street_names(columbus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running my audits, I created the appropriate mapping dicts for each of the addr types.\n",
    "\n",
    "The cities just had a few capitalizations and extra state notations to get rid of, there was only one entry for counties, I plan to ignore and delete the Alabama & Georgia elements as they should not be here, I'm going to set all the country codes to the 3 letter version, and there were some zip codes that needed to be more uniform.\n",
    "\n",
    "Once that was done, the last step was to shape the elements into the specified format and output it to a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columbusData=process_map(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Database\n",
    "### Step 3: Creating and Adding the Dataset to MongoDB\n",
    "Now that the cleaning process is done, I can go ahead and add the json file to a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost:27017')\n",
    "db = client.udacity_db\n",
    "db.columbusOSM.delete_many({})\n",
    "db.columbusOSM.insert_many(columbusData);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Querying the Database\n",
    "Now all that's left is to query the database for various information. I'll start with the size of the database and how many documents there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180387893\n"
     ]
    }
   ],
   "source": [
    "aggregate=[{'$collStats':{'storageStats':{}}}]\n",
    "for a in db.columbusOSM.aggregate(aggregate):\n",
    "    print a['storageStats']['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.columbusOSM.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's over 800,000 documents in about 172 MB of data. Next up is how many unique users have contributed to this. I already checked the number earlier, so it should be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.columbusOSM.find().distinct('created.user'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's 10 less than my original number, so it seems that some users weren't part of the final dataset that got added in. Next, I'll query to find the number of nodes and ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 17, u'_id': u'multipolygon'}\n",
      "{u'count': 84846, u'_id': u'way'}\n",
      "{u'count': 4, u'_id': u'multi-storey'}\n",
      "{u'count': 720798, u'_id': u'node'}\n"
     ]
    }
   ],
   "source": [
    "aggregate=[{'$group':{'_id':'$type', 'count':{'$sum':1}}}]\n",
    "for a in db.columbusOSM.aggregate(aggregate):\n",
    "    print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relating this to my original tag count of the XML file, all but 1 of the node & way tags made it into the final database.\n",
    "\n",
    "Next I'll take a look at what the most common amenities are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 799423, u'_id': None}\n",
      "{u'count': 2566, u'_id': u'parking'}\n",
      "{u'count': 741, u'_id': u'place_of_worship'}\n",
      "{u'count': 550, u'_id': u'restaurant'}\n",
      "{u'count': 505, u'_id': u'school'}\n",
      "{u'count': 261, u'_id': u'fast_food'}\n",
      "{u'count': 141, u'_id': u'fuel'}\n",
      "{u'count': 110, u'_id': u'bench'}\n",
      "{u'count': 98, u'_id': u'bank'}\n",
      "{u'count': 94, u'_id': u'grave_yard'}\n"
     ]
    }
   ],
   "source": [
    "aggregate=[{'$group':{'_id':'$amenity', 'count':{'$sum':1}}},\n",
    "           {'$sort':{'count':-1}},\n",
    "           {'$limit':10}]\n",
    "for a in db.columbusOSM.aggregate(aggregate):\n",
    "    print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, earlier when I ran my state audits, I saw that there were entries for Alabama & Georgia in the dataset. I'm going to look for those entries now that they're a little cleaner to look at and determine whether or not they belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('5a01e94fa481d92628dc7689'),\n",
      " u'address': {u'city': u'Adamsville',\n",
      "              u'housenumber': u'35005',\n",
      "              u'postcode': u'35005',\n",
      "              u'state': u'Alabama',\n",
      "              u'street': u'East Broad Street'},\n",
      " u'amenity': u'fuel',\n",
      " u'created': {u'changeset': u'52339826',\n",
      "              u'timestamp': u'2017-09-24T21:28:47Z',\n",
      "              u'uid': u'339581',\n",
      "              u'user': u'nyuriks',\n",
      "              u'version': u'4'},\n",
      " u'id': u'1278853280',\n",
      " u'name': u'Marathon',\n",
      " u'opening_hours': u'sasqsq',\n",
      " u'operator': u'sqsqsqsqsqs',\n",
      " u'pos': [39.9846503, -82.8153421],\n",
      " u'type': u'node',\n",
      " u'wikidata': u'Q4590796',\n",
      " u'wikipedia': u'en:1995 World Marathon Cup'}\n",
      "{u'_id': ObjectId('5a01e958a481d92628e1ded1'),\n",
      " u'address': {u'city': u'Columbus',\n",
      "              u'housenumber': u'1773',\n",
      "              u'postcode': u'43212',\n",
      "              u'state': u'ga',\n",
      "              u'street': u'West Fifth Avenue'},\n",
      " u'amenity': u'restaurant',\n",
      " u'created': {u'changeset': u'45885490',\n",
      "              u'timestamp': u'2017-02-07T13:21:06Z',\n",
      "              u'uid': u'5276256',\n",
      "              u'user': u'pekingdynasty',\n",
      "              u'version': u'1'},\n",
      " u'cuisine': u'Chinese',\n",
      " u'id': u'4671954336',\n",
      " u'name': u'Peking Dynasty',\n",
      " u'phone': u'614-488-8128',\n",
      " u'pos': [39.9890527, -83.053904],\n",
      " u'type': u'node',\n",
      " u'website': u'http://pekingdynasty.net'}\n"
     ]
    }
   ],
   "source": [
    "query={'address.state':{'$exists':1, '$ne':'OH'}}\n",
    "for q in db.columbusOSM.find(query):\n",
    "    pprint.pprint(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first document is definitely not in Columbus, OH. So I'll delete that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query={'address.state':'Alabama'}\n",
    "db.columbusOSM.delete_one(query);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second document however, seems to have just made a mistake on the state, as the name, address, city, & postcode are all correct, so for this one, I'll simply update the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query={'address.state':'ga'}\n",
    "peking=db.columbusOSM.find_one(query)\n",
    "peking['address']['state']='OH'\n",
    "db.columbusOSM.replace_one(query, peking);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were also some invalid postcodes in the data, but getting the correct values for those would be a little tedious, so instead of updating those, I'm just going to remove the attributes for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 803891, u'_id': None}\n",
      "{u'count': 333, u'_id': u'43017'}\n",
      "{u'count': 218, u'_id': u'43235'}\n",
      "{u'count': 111, u'_id': u'43221'}\n",
      "{u'count': 97, u'_id': u'43215'}\n",
      "{u'count': 90, u'_id': u'43210'}\n",
      "{u'count': 87, u'_id': u'43026'}\n",
      "{u'count': 78, u'_id': u'43212'}\n",
      "{u'count': 72, u'_id': u'43201'}\n",
      "{u'count': 60, u'_id': u'43202'}\n"
     ]
    }
   ],
   "source": [
    "query={'$nor':[{'address.postcode':{'$exists':0}},\n",
    "               {'address.postcode':{'$regex':'43[0-9]{3}'}}]}\n",
    "db.columbusOSM.update_many(query, {'$unset':{'address.postcode':''}})\n",
    "\n",
    "aggregate=[{'$group':{'_id':'$address.postcode', 'count':{'$sum':1}}},\n",
    "           {'$sort':{'count':-1}},\n",
    "           {'$limit':10}]\n",
    "for a in db.columbusOSM.aggregate(aggregate):\n",
    "    print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for my curiosity, I'm going to see which city has the most information in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 803790, u'_id': None}\n",
      "{u'count': 998, u'_id': u'Columbus'}\n",
      "{u'count': 345, u'_id': u'Dublin'}\n",
      "{u'count': 98, u'_id': u'Upper Arlington'}\n",
      "{u'count': 85, u'_id': u'Hilliard'}\n",
      "{u'count': 58, u'_id': u'Pickerington'}\n",
      "{u'count': 37, u'_id': u'Powell'}\n",
      "{u'count': 34, u'_id': u'Lewis Center'}\n",
      "{u'count': 30, u'_id': u'Worthington'}\n",
      "{u'count': 30, u'_id': u'Galloway'}\n"
     ]
    }
   ],
   "source": [
    "aggregate=[{'$group':{'_id':'$address.city', 'count':{'$sum':1}}},\n",
    "           {'$sort':{'count':-1}},\n",
    "           {'$limit':10}]\n",
    "for a in db.columbusOSM.aggregate(aggregate):\n",
    "    print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the main city of Columbus has more documents rather than any of its suburbs.\n",
    "### Additional Improvements\n",
    "After going through some of the documents, one of the things that bothered me the most was the lack of complete address information. While many had no information at all, several were only partially complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2771\n"
     ]
    }
   ],
   "source": [
    "query={'address':{'$exists':1}}\n",
    "print db.columbusOSM.find(query).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 3000 documents in over 800,000 documents had some address information, with even less having it fully completed.\n",
    "\n",
    "One possible solution for this would be to figure out the latitude and longitude ranges in which certain geo-specific attributes fall under, like post codes, cities/districts, counties, and then states/countries on a larger scale.\n",
    "\n",
    "This solution would be extremely tedious to do manually, as it would require setting boundaries for the millions of combinations of the different address notations around the world, but it seems like something that could be possible with machine learning algorithms. Once this algorithm was implemented, it could even be refined to the degree that it is able to fill in street names on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "I enjoyed this project. It gave me a lot of practice with several Python libraries and helped me to understand more of what Data Science & Analysis is all about.\n",
    "\n",
    "For this dataset in particular, there are certainly areas that need improvement, mostly concerning missing data and validity of it, but I think it has been cleaned fairly well to be sufficiently readable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
